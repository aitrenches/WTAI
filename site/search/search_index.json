{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Advanced Data Management Masterclass","text":"<p>Accelerate measurable business outcomes with AI and modern data management\u2014built for Nigerian Oil &amp; Gas and adaptable across industries. From workforce transformation to platform governance, this masterclass turns strategy into production\u2011ready pilots in 90 days.</p> <p>Day tracks</p> <ul> <li> <p>Day 4 \u2014 Workforce Transformation &amp; Analytics: strategy to operating model, reference architectures, AI in operations, data products, roles/culture, and workshop.</p> </li> <li> <p>Day 5 \u2014 Implementation Planning &amp; Governance: investment and portfolio shaping, federated governance, NDPA 2023 compliance, quality/observability, platform blueprint, and workshop.</p> </li> </ul> <p>Start here</p> <ul> <li> <p>Day 4 \u2014 Overview</p> </li> <li> <p>Day 5 \u2014 Overview</p> </li> </ul> <p>Tools and references</p> <ul> <li>Case Studies</li> <li>Worksheets</li> <li>Resources</li> <li>Glossary</li> </ul>"},{"location":"case-studies/","title":"Cross-Industry Case Studies","text":"<p>These case studies will be referenced across Day 4 and Day 5 to connect strategy, architecture, governance, compliance, and platform execution. Each example maps value to KPI trees, defines data products and contracts, specifies SLO/SLI reliability targets, and identifies controls under the federated governance model.</p> <p>Learning Objective (Analyze): Deconstruct each use case into data products, contracts, SLOs, controls, and platform components; quantify KPI impact and outline a 90\u2011day pilot.</p>"},{"location":"case-studies/#case-study-1-oil-gas-upstream-predictive-maintenance","title":"Case Study 1: Oil &amp; Gas Upstream Predictive Maintenance","text":"<ul> <li>Problem: Unplanned downtime from equipment failure and financial penalties from gas flaring.</li> <li>Data Products:<ul> <li>Sensor Telemetry Product: Real-time data from wellheads and facilities.</li> <li>Maintenance Work Order Product: Historical and current maintenance logs.</li> <li>Emissions Reporting Product: Flaring volume and environmental data.</li> </ul> </li> <li>Key Controls: Attribute-Based Access Control (ABAC) on specific wells; strict PII segregation in personnel logs; end-to-end data lineage for auditing emissions reports.</li> <li>Target KPIs: Increase equipment uptime by +2-4%, reduce OPEX by -5-8%, and reduce flaring volumes by -10-20%.</li> <li>Architecture: Streaming ingestion \u2192 Medallion Lakehouse (Bronze/Silver/Gold) \u2192 Feature Store for PdM \u2192 RAG for SOP retrieval. Governance plane: lineage, ABAC, quality SLIs.</li> <li>Data Contract Highlights: schema/versioning; freshness SLO 99.9% &lt;5m; completeness SLO \u226599.5% wells/day; accuracy SLO \u226598% valid pressure range.</li> <li>Governance/Compliance: masking at Silver for personnel references; ABAC by asset/region; DPIA if model decisions affect worker scheduling.</li> <li>90\u2011Day Pilot Target: one compressor asset; alert precision \u226590%; false alarms \u221250%; ROI quantified against avoided downtime.</li> </ul>"},{"location":"case-studies/#case-study-2-procurement-epicforge","title":"Case Study 2: Procurement (EPICFORGE)","text":"<ul> <li>Current Pain Points:</li> <li>Manual, time\u2011consuming RFQ creation, vendor communications, and bid analysis \u2192 weeks of cycle time and errors</li> <li>Slow vendor response rates due to complex submissions and low transparency</li> <li>Inconsistent data and formats across vendors; difficult comparisons; risk of omissions</li> <li>Lack of analytics on spend patterns, vendor performance, and optimization opportunities</li> <li>EPICFORGE Solution:</li> <li>AI\u2011powered automation: intelligent RFQ generation, automated vendor matching, smart bid analysis (manual effort \u221260%)</li> <li>Seamless vendor experience: portal with template\u2011based submissions (response rate +40%)</li> <li>Standardized workflows: template\u2011driven processes ensure consistency and comparable bids</li> <li>Comprehensive analytics: real\u2011time spend, vendor performance, and savings opportunities</li> <li>Data Products:</li> <li>RFQ Master Product: structured RFQ with schema and semantics</li> <li>Vendor Profile/Product: capabilities, certifications, performance history</li> <li>Bid Submission Product: normalized line\u2011items and terms</li> <li>Spend Analytics Product: aggregated transactions and savings realized</li> <li>Data Contract Highlights: schema and mandatory semantics; freshness SLO (bid window updates &lt;1m); completeness SLO \u226599% required fields; accuracy rules for currency/tax calculations.</li> <li>Architecture: Event\u2011driven ingestion from portal \u2192 Silver normalization \u2192 Gold analytics; optional RAG for policy/T&amp;Cs lookup; lineage for auditability.</li> <li>Governance/Compliance: ABAC by role (ProcurementManager, Auditor) and purpose (Sourcing vs Reporting); PII tokenization for vendor contacts at Silver; DPIA if processing sensitive identifiers.</li> <li>KPIs: cycle time \u221230\u201360%; vendor participation +40%; negotiated savings uplift; maverick spend \u221210\u201320%.</li> <li>90\u2011Day Pilot Target: one category (e.g., MRO spares) with 10 vendors; implement portal templates, normalization pipeline, and analytics dashboard; demonstrate cycle\u2011time reduction and savings.</li> </ul>"},{"location":"case-studies/#case-study-3-nigerian-renewable-energy-asset-performance","title":"Case Study 3: Nigerian Renewable Energy Asset Performance","text":"<ul> <li>Problem: Failures and service delays for distributed solar inverters as adoption grows.</li> <li>Data Products:<ul> <li>Asset Telemetry Product: Performance data from solar assets.</li> <li>Service Ticketing Product: Customer issue and event logs.</li> <li>Parts Inventory Product: Availability of replacement parts.</li> </ul> </li> <li>Key Controls: Customer consent management for data usage; localized language support for field operations using the N-ATLAS model.</li> <li>Target KPIs: Reduce Mean Time To Repair (MTTR) by -20-35%; increase total energy yield by +3-7%.</li> <li>Architecture: Edge buffering for intermittent connectivity \u2192 central lakehouse; anomaly detection; multilingual RAG for manuals.</li> <li>Data Contract Highlights: telemetry schema; freshness SLO &lt;5m; completeness SLO \u226599%; accuracy rules per device class.</li> <li>Governance/Compliance: consent management; localized language support with N\u2011ATLAS; ABAC by region/installer.</li> <li>90\u2011Day Pilot Target: 1,000 inverters; MTTR \u221220\u201335%; yield +3\u20137%; publish DPO\u2011owned contract and SLOs.</li> </ul>"},{"location":"day-4/","title":"From Strategy to Operating Model","text":"<p>Welcome to Day 4. Today, we bridge the gap between business strategy and technical execution. We will focus on how to identify high-value opportunities for data and AI, select the right architectural patterns to deliver on them, and establish an operating model that treats data as a core business product. Each session is designed to be interactive, culminating in a workshop where you will design a 90-day pilot project.</p>"},{"location":"day-4/#learning-outcomes","title":"Learning Outcomes","text":"<p>By the end of today, you will be able to:</p> <ul> <li>Align AI and data investments to specific business KPI trees (e.g., uptime, OPEX, safety).</li> <li>Select a baseline architecture with clear non-functional requirements like latency, SLOs, and cost.</li> <li>Draft a data product definition and its corresponding data contract.</li> <li>Define evaluation criteria and control points for AI-driven workflows, including human-in-the-loop systems.</li> </ul>"},{"location":"day-4/#agenda","title":"Agenda","text":"<ol> <li> <p>Why Now: Business Value from Data + AI</p> <ul> <li>Focus: Connecting data initiatives directly to O&amp;G value drivers and KPIs.</li> <li>Artifacts: KPI Tree Template, Value Hypothesis Canvas.</li> </ul> </li> <li> <p>Reference Architectures for Analytics in Operations</p> <ul> <li>Focus: Exploring modern, platform-agnostic patterns like the lakehouse, streaming, and vector search.</li> <li>Artifacts: Reference Architecture Map.</li> </ul> </li> <li> <p>AI in Operations: PdM, Optimization, and Agentic Workflows</p> <ul> <li>Focus: Practical application of AI, from predictive maintenance (PdM) to LLM-based agents, with essential guardrails.</li> <li>Artifacts: RAG Risk Register, Evaluation Rubric.</li> </ul> </li> <li> <p>The Data Product Operating Model &amp; Data Contracts</p> <ul> <li>Focus: Shifting from project-based delivery to a product-oriented model for data assets.</li> <li>Artifacts: Data Product Canvas, Data Contract Template.</li> </ul> </li> <li> <p>Workforce and Culture: Roles, Skills, and Adoption</p> <ul> <li>Focus: Identifying the new roles and skills required to succeed, and planning for cultural change.</li> <li>Artifacts: RACI Template, Communications Plan Outline.</li> </ul> </li> <li> <p>Interactive Workshop: Human-Machine Collaboration Redesign</p> <ul> <li>Focus: Applying the day's concepts to a real-world operational process to define a 90-day pilot target.</li> <li>Artifacts: Workshop Board Export.</li> </ul> </li> </ol>"},{"location":"day-5/","title":"Day 5: Implementation, Governance, and Compliance","text":"<p>Welcome to Day 5. Today, we get practical about implementation. We will cover how to prioritize your data and AI portfolio, establish robust governance and compliance frameworks\u2014with a specific focus on Nigeria's NDPA 2023\u2014and create a tangible platform roadmap. The day culminates in a workshop where you will transform your pilot idea from Day 4 into a concrete implementation plan.</p>"},{"location":"day-5/#learning-outcomes","title":"Learning Outcomes","text":"<p>By the end of today, you will be able to:</p> <ul> <li>Prioritize a pilot portfolio using ROI and risk scoring methods.</li> <li>Define a minimal viable control set for AI and data governance, including a clear ownership model.</li> <li>Establish data SLOs/SLIs, lineage, and observability practices to ensure reliability.</li> <li>Integrate Nigeria Data Protection Act (NDPA) 2023 obligations directly into your delivery lifecycle.</li> </ul>"},{"location":"day-5/#agenda","title":"Agenda","text":"<ol> <li> <p>Investment Strategy and Portfolio Shaping</p> <ul> <li>Focus: Using FinOps principles to score and prioritize data/AI initiatives.</li> <li>Artifacts: ROI Calculator, Risk Log.</li> </ul> </li> <li> <p>Governance for the AI Era</p> <ul> <li>Focus: Mapping policies to technical controls for data, models, and access in a platform-agnostic way.</li> <li>Artifacts: Governance Controls Checklist.</li> </ul> </li> <li> <p>Compliance Focus: Nigeria NDPA 2023 and Global Parity</p> <ul> <li>Focus: A deep dive into the NDPA 2023, NDPC requirements, and O&amp;G sector nuances.</li> <li>Artifacts: DPIA Template, Data Transfer Assessment Outline.</li> </ul> </li> <li> <p>Quality, Observability, and Reliability</p> <ul> <li>Focus: Defining and implementing Service Level Objectives (SLOs) and Indicators (SLIs) for your data products.</li> <li>Artifacts: Lineage + Observability Checklist.</li> </ul> </li> <li> <p>Platform Blueprint and Reference Implementation Plan</p> <ul> <li>Focus: Comparing architectural patterns (e.g., mesh vs. fabric) and designing a phased implementation roadmap.</li> <li>Artifacts: Platform Roadmap Storyboard.</li> </ul> </li> <li> <p>Interactive Workshop: Pilot Plan to Production Path</p> <ul> <li>Focus: Creating an executive one-pager and an IT implementation brief for your pilot project.</li> <li>Artifacts: Executive One-Pager, Implementation Brief.</li> </ul> </li> </ol>"},{"location":"day4-ai-in-operations/","title":"AI in Operations: PdM, Optimization, and Agentic Workflows","text":""},{"location":"day4-ai-in-operations/#introduction-activating-the-architecture","title":"Introduction: activating the architecture","text":"<p>We now turn on the factory we designed. This session focuses on applying AI safely and reliably in operations across three patterns: predictive analytics (PdM), prescriptive analytics (optimization), and agentic workflows with governance. Key artifacts: RAG Risk Register and Evaluation Rubric.</p>"},{"location":"day4-ai-in-operations/#pattern-1-predictive-maintenance-pdmabbrpredictive-maintenance-pipelines","title":"Pattern 1: Predictive Maintenance (PdM{:abbr=\"Predictive Maintenance\"}) pipelines","text":"<p>A PdM solution is a living pipeline on top of your platform, not a one\u2011off model.</p> <pre><code>flowchart LR\n    A[Sensor Data Ingest] --&gt; B{Data Quality Checks}\n    B --&gt; C[Feature Engineering]\n    C --&gt; D[Feature Store]\n    D --&gt; E[Model Training]\n    E --&gt; F((Model Registry))\n    F --&gt; G[Model Serving API]\n    G --&gt; H[Operational Systems]\n    F -- Retraining Trigger --&gt; E\n\n    subgraph Monitoring\n        M1[Data Drift]\n        M2[Model Performance]\n    end\n    G -- Feedback Loop --&gt; M2\n    A -- Feedback Loop --&gt; M1\n    M1 --&gt; F\n    M2 --&gt; F</code></pre> <ul> <li>Ingest &amp; quality: automated QA for missing/offline/out\u2011of\u2011range signals.</li> <li>Feature engineering: domain features (e.g., rolling averages) become reusable assets.</li> <li>Feature/embedding store: promotes consistency and reuse across models.</li> <li>Model registry: versions, metrics, lineage, approvals.</li> <li>Serving &amp; monitoring: real\u2011time scoring with drift/performance monitoring and retraining triggers.</li> </ul> <p>Risk\u2011aware PdM decisioning <pre><code>flowchart LR\n  Score[Risk Score] --&gt; Thresh{Above Threshold?}\n  Thresh -- Yes --&gt; WO[Draft Work Order]\n  WO --&gt; HILT[Human Review]\n  HILT -- Approve --&gt; Schedule[Schedule Maintenance]\n  HILT -- Reject --&gt; Observe[Continue Monitoring]\n  Thresh -- No --&gt; Observe</code></pre></p>"},{"location":"day4-ai-in-operations/#pattern-2-optimization-and-prescriptive-analytics","title":"Pattern 2: Optimization and prescriptive analytics","text":"<p>Prediction tells you what might happen; optimization tells you what to do subject to constraints.</p> <p>Examples - Production allocation: optimal flow configuration to meet targets at lowest cost. - Spares planning: inventory levels by site balancing downtime risk and cost. - Energy balancing (renewables): schedule charge/discharge vs forecast prices and solar.</p> <p>Techniques include operations research (linear/mixed\u2011integer programming) and reinforcement learning for policy search under constraints.</p>"},{"location":"day4-ai-in-operations/#pattern-3-agentic-workflows-with-guardrails","title":"Pattern 3: Agentic workflows with guardrails","text":"<p>Agents plan and use tools; governance ensures safe operation. RAG{:abbr=\"Retrieval\u2011Augmented Generation\"} provides grounded knowledge; policies enforce input/output safety and traceability.</p> <pre><code>sequenceDiagram\n  participant U as User/Operator\n  participant A as App/Agent\n  participant R as Retriever\n  participant V as Vector+Catalog\n  participant P as Policy/Guardrails\n  participant L as LLM\n\n  U-&gt;&gt;A: Query / Task\n  A-&gt;&gt;P: Policy check (PII, scope, rate)\n  P--&gt;&gt;A: Permit with constraints\n  A-&gt;&gt;R: Retrieve with filters (domain, freshness)\n  R-&gt;&gt;V: Hybrid search (keyword + vector)\n  V--&gt;&gt;R: Context (ranked, deduped)\n  R--&gt;&gt;A: Context bundle\n  A-&gt;&gt;L: Prompt + context\n  L--&gt;&gt;A: Response\n  A-&gt;&gt;P: Output checks (toxicity, leakage)\n  P--&gt;&gt;A: Approve/Redact\n  A--&gt;&gt;U: Answer + trace (sources, lineage)</code></pre> <p>Checklist for governed agents - Input policy checks before retrieval. - Filtered retrieval with domain/freshness constraints. - Output checks for safety and leakage; redact when needed. - Traceability with citations; local language support (e.g., N\u2011ATLAS) when appropriate.</p>"},{"location":"day4-ai-in-operations/#humanintheloop-and-managing-risk","title":"Human\u2011in\u2011the\u2011loop and managing risk","text":"<p>Safety\u2011critical environments require human\u2011machine teaming. Use: - RAG Risk Register to list risks, mitigations, and owners (hallucinations, stale docs, misuse). - Evaluation Rubric to define correctness, relevance, safety, completeness.</p>"},{"location":"day4-ai-in-operations/#conclusion-and-transition","title":"Conclusion and transition","text":"<p>You now have three AI patterns operating on your platform: forecasting (PdM), deciding (optimization), and assisting (agents) with governance. Next: the Data Product Operating Model and Data Contracts\u2014who owns what, how backlogs and SLOs/SLA are managed, and how value is delivered at scale.</p>"},{"location":"day4-data-product-and-contracts/","title":"The Data Product Operating Model &amp; Data Contracts","text":""},{"location":"day4-data-product-and-contracts/#introduction-the-scaling-problem","title":"Introduction: the scaling problem","text":"<p>Many data initiatives fail to scale not because of technology, but because of the operating model. Treating data as a byproduct managed by a central team doesn\u2019t scale. Shift from project/service\u2011ticket mindset to product ownership. Key artifacts: Data Product Canvas and Data Contract Template.</p>"},{"location":"day4-data-product-and-contracts/#the-old-way-the-centralized-bottleneck","title":"The old way: the centralized bottleneck","text":"<p>Central teams become backlogs; context is lost; ownership is unclear; quality suffers; pipelines are brittle.</p> <pre><code>graph TD\n    subgraph Business_Domains[Business Domains]\n        D1(Upstream Ops)\n        D2(Refining)\n        D3(Logistics)\n    end\n    subgraph Central_Data_Team[Central Data Team]\n        P(Platform Engineers)\n        E(Data Engineers)\n        A(Analysts)\n    end\n    subgraph Data_Consumers[Data Consumers]\n        C1(BI Reports)\n        C2(AI Models)\n        C3(Finance App)\n    end\n\n    D1 -- Ticket: Need well data --&gt; E\n    D2 -- Ticket: Refinery sensor data --&gt; E\n    D3 -- Ticket: Shipping data --&gt; E\n\n    E -- Backlog --&gt; P\n    E -- Data is ready --&gt; A\n\n    A --&gt; C1\n    A --&gt; C2\n    E --&gt; C3\n\n    style E fill:#ffcccc,stroke:#333</code></pre> <p>Problems - Loss of context and domain nuance - No clear ownership for correctness - Low quality and reactive cleanup - Fragile downstream dependencies</p>"},{"location":"day4-data-product-and-contracts/#a-new-paradigm-treating-data-as-a-product-daapabbrdataasaproduct","title":"A new paradigm: treating data as a product (DaaP{:abbr=\"Data\u2011as\u2011a\u2011Product\"})","text":"<p>Decentralize ownership to domains; the central team becomes a platform enabling self\u2011service.</p> <pre><code>graph TD\n    subgraph Domain_Upstream[Domain: Upstream Ops]\n        Owner1(Product Owner)\n        Team1(Engineers)\n        DP1[Sensor Telemetry Product]\n        Team1 --&gt; DP1\n        Owner1 --&gt; DP1\n    end\n    subgraph Domain_Logistics[Domain: Logistics]\n        Owner2(Product Owner)\n        Team2(Engineers)\n        DP2[Vessel Tracking Product]\n        Team2 --&gt; DP2\n        Owner2 --&gt; DP2\n    end\n    subgraph Consumers\n        C1(Predictive Maintenance App)\n        C2(Supply Chain Optimization Model)\n    end\n\n    DP1 -- Contract --&gt; C1\n    DP2 -- Contract --&gt; C2\n    DP1 -- Contract --&gt; C2</code></pre> <p>Product includes data, code, infra, metadata, owner, version, and interface. Domains create; platform team provides tooling and guardrails.</p>"},{"location":"day4-data-product-and-contracts/#the-api-for-data-data-contracts","title":"The API for data: data contracts","text":"<p>A data contract is a formal, machine\u2011readable agreement between producer and consumers. It defines expectations and becomes part of CI/CD.</p> <p>Contract lifecycle <pre><code>flowchart TB\n  Draft[Draft Contract] --&gt; Review[Domain Review]\n  Review --&gt; Approve[Governance Approval]\n  Approve --&gt; Enforce[CI/CD Enforcement]\n  Enforce --&gt; Observe[SLI/SLO Monitoring]\n  Observe --&gt; Version{Need Change?}\n  Version -- Yes --&gt; Deprecate[Deprecate v1, Publish v2]\n  Version -- No --&gt; Operate[Operate]</code></pre></p> <p>Contract components - Schema: columns, types, constraints; versioning for changes - Semantics: precise business meaning (e.g., prod_vol: daily crude volume, bbl at STP) - Quality &amp; reliability (SLOs/SLIs):   - Freshness: updated daily by 06:00 AM WAT   - Completeness: monthly data &gt; 99.5% of active wells   - Accuracy: percent of readings within valid ranges - PII &amp; security: fields with PII; masking/tokenization; access tiers - Lifecycle &amp; deprecation: support windows per version; deprecation policy</p> <p>Enforcement: contract is code in the deployment pipeline; violating changes fail builds.</p>"},{"location":"day4-data-product-and-contracts/#interactive-your-first-data-product-canvas","title":"Interactive: your first data product canvas","text":"<p>Choose a core dataset for your pilot (e.g., Sensor Telemetry Product or User Intent Signals). Fill the canvas: owner, consumers, purpose, 1\u20132 critical SLOs.</p>"},{"location":"day4-data-product-and-contracts/#conclusion-and-transition","title":"Conclusion and transition","text":"<p>This operating model\u2014decentralized ownership + data contracts + platform enablement\u2014scales value without scaling chaos. Next: workforce and culture\u2014roles, skills, and adoption mechanics to make the model stick.</p>"},{"location":"day4-reference-architectures/","title":"Reference Architectures for Analytics in Operations","text":""},{"location":"day4-reference-architectures/#introduction-from-why-to-how","title":"Introduction: from why to how","text":"<p>We move from measurable value hypotheses to technical blueprints. The goal is to select a baseline, platform\u2011agnostic architecture and define key non\u2011functional requirements (latency, cost) for your pilot. We focus on patterns, not vendors; you can realize these on Azure, AWS, SAP, or hybrid.</p>"},{"location":"day4-reference-architectures/#the-modern-data-lakehouse","title":"The modern data lakehouse","text":"<p>Warehouses were reliable but inflexible; lakes were flexible but messy. The lakehouse combines both, with the Medallion pattern to refine data from raw to business\u2011ready.</p> <pre><code>flowchart LR\n  subgraph Raw_Ingestion[Raw Ingestion]\n    S1[Source Systems]\n  end\n  subgraph Lakehouse\n    B((Bronze)) -- Cleansing --&gt; S((Silver))\n    S -- Aggregation --&gt; G((Gold))\n  end\n  subgraph Consumption\n    BI[BI &amp; Analytics]\n    ML[AI/ML Models]\n  end\n\n  S1 --&gt; B\n  G --&gt; BI\n  S --&gt; ML\n\n  style B fill:#CD7F32,stroke:#333\n  style S fill:#C0C0C0,stroke:#333\n  style G fill:#FFD700,stroke:#333</code></pre> <ul> <li>Bronze (raw): complete historical archive; raw sensor readings, JSON from apps, reports.</li> <li>Silver (cleansed &amp; conformed): standardized formats, joins, validated single source of truth.</li> <li>Gold (aggregated &amp; business\u2011ready): KPI\u2011level views feeding BI and executive reporting.</li> </ul>"},{"location":"day4-reference-architectures/#handling-velocity-streaming-and-edge-analytics","title":"Handling velocity: streaming and edge analytics","text":"<p>Operational use cases need data in motion. A streaming bus ingests high\u2011velocity events; edge computing filters/aggregates near sources to reduce latency and bandwidth while keeping critical alerts real\u2011time.</p> <pre><code>flowchart LR\n  subgraph Edge[Edge Location]\n    S1[SCADA/IoT] --&gt; G1[Edge Gateway]\n    G1 -- Filter &amp; Aggregate --&gt; G1\n  end\n\n  subgraph Central[Central Platform]\n    Q[Streaming Bus]\n    LH[Lakehouse]\n    APP[Real\u2011time Apps]\n  end\n\n  G1 -- Critical Alerts &amp; Summaries --&gt; Q\n  Q --&gt; LH\n  Q --&gt; APP</code></pre> <p>Examples - O&amp;G: edge detects pressure anomalies; alerts via streaming bus; summaries land in lakehouse. - Renewables: edge buffers telemetry during outages, streams when restored. - Telecom: streaming feeds real\u2011time churn scoring.</p>"},{"location":"day4-reference-architectures/#unlocking-unstructured-data-retrieval-architectures","title":"Unlocking unstructured data: retrieval architectures","text":"<p>Hybrid search powers RAG{:abbr=\"Retrieval\u2011Augmented Generation\"} systems: combine keyword search for precision with vector search for semantic similarity.</p> <pre><code>sequenceDiagram\n  participant U as User\n  participant App as RAG Application\n  participant R as Retriever\n  participant K as Keyword Index\n  participant V as Vector Index\n\n  U-&gt;&gt;App: What's the SOP for a high\u2011pressure shutdown?\n  App-&gt;&gt;R: Retrieve relevant docs\n  R-&gt;&gt;K: Search SOP, pressure, shutdown\n  K--&gt;&gt;R: Doc A, Doc C\n  R-&gt;&gt;V: Semantic search\n  V--&gt;&gt;R: Doc A, Doc B\n  R--&gt;&gt;App: Combined results: Doc A, B, C</code></pre> <p>This lets engineers ask natural\u2011language questions and get grounded answers with citations.</p> <p>Retrieval quality and guardrails <pre><code>flowchart TB\n  Q[User Query] --&gt; F[Filters: domain, freshness]\n  F --&gt; H[Hybrid Search: keyword + vector]\n  H --&gt; D[Deduplicate &amp; Rank]\n  D --&gt; C[Context Pack]\n  C --&gt; G[Guardrails: PII/Leakage Check]\n  G --&gt; LLM[LLM Generate]\n  LLM --&gt; V[Validate &amp; Cite Sources]</code></pre></p>"},{"location":"day4-reference-architectures/#the-full-blueprint","title":"The full blueprint","text":"<p>A modern platform fuses lakehouse, streaming/edge, retrieval, and a governance plane.</p> <pre><code>flowchart LR\n  subgraph Ingestion\n    S1[SCADA/IoT] --&gt; G1[Gateway/Edge]\n    S2[Enterprise Apps] --&gt; Q[Streaming Bus]\n  end\n  subgraph Platform\n    G1 --&gt; Q\n    Q --&gt; BR[Batch/Stream Refinement]\n    BR --&gt; LZ[Lakehouse Bronze]\n    LZ --&gt; LS[Lakehouse Silver]\n    LS --&gt; LG[Lakehouse Gold]\n    LS --&gt; FS[Feature/Embedding Store]\n  end\n  subgraph Serving\n    FS --&gt; SV[Serving/API]\n    LG --&gt; BI[BI/Semantics]\n  end\n  subgraph Consumers\n    BI --&gt; Users\n    SV --&gt; Apps\n  end\n  subgraph Governance[Governance Plane]\n    GL[Lineage]\n    AC[Access Control]\n    QL[Quality/SLIs]\n  end\n  LZ --- GL\n  LS --- AC\n  LG --- QL</code></pre> <p>Use this map to select components for your 90\u2011day pilot: do you need real\u2011time streaming, vector search, both, or neither?</p>"},{"location":"day4-why-now/","title":"Why Now? Business Value from Data + AI","text":""},{"location":"day4-why-now/#introduction-setting-the-stage-000005","title":"Introduction &amp; setting the stage (0:00\u20130:05)","text":"<p>Good morning and welcome to Day 4 of the Advanced Data Management Masterclass. Over the next two days, we connect modern data and AI capabilities directly to business outcomes. Today is about moving from strategy to an operating model. By the end of the day, you will have designed a 90\u2011day pilot for your organization.</p> <p>In this first hour we answer: Why now? Why is this more urgent than three or five years ago? We anchor the discussion in business value and learn to translate every data initiative into clear impact on key performance indicators (KPIs).</p>"},{"location":"day4-why-now/#the-convergence-three-forces-driving-change","title":"The convergence: three forces driving change","text":""},{"location":"day4-why-now/#1-economic-drivers","title":"1) Economic drivers","text":"<ul> <li>Oil &amp; Gas: maximize operational efficiency, improve safety, navigate the energy transition. Targets include reducing OPEX, increasing production uptime, and minimizing environmental impact.</li> <li>Telecommunications: reduce churn and defend ARPU in a hyper\u2011competitive market.</li> <li>Renewables: efficiently manage a rapidly growing fleet of distributed assets.</li> </ul>"},{"location":"day4-why-now/#2-technology-maturity-and-affordability","title":"2) Technology maturity and affordability","text":"<p>Cloud storage/compute costs have dropped. Modern architectural patterns like the lakehouse let us process, store, and analyze petabyte\u2011scale sensor data in near real\u2011time\u2014formerly cost\u2011prohibitive.</p>"},{"location":"day4-why-now/#3-ai-accessibility","title":"3) AI accessibility","text":"<p>Large Language Models and Retrieval\u2011Augmented Generation (RAG{:abbr=\"Retrieval\u2011Augmented Generation\"}) unlock value from unstructured data such as maintenance reports, safety manuals, and geological surveys. Locally, N\u2011ATLAS supports Yoruba, Hausa, Igbo, and Nigerian\u2011accented English, making AI directly applicable to field operations in Nigeria.</p>"},{"location":"day4-why-now/#speaking-the-language-of-value-kpi-trees","title":"Speaking the language of value: KPI trees","text":"<p>Use KPI Trees to deconstruct a strategic objective into measurable drivers that data/AI can influence.</p> <pre><code>graph TD\n    A[Improve Financial Performance] --&gt; B[Reduce OPEX]\n    A --&gt; C[Increase Revenue]\n    B --&gt; D[Increase Production Uptime]\n    B --&gt; E[Optimize Maintenance Costs]\n    D --&gt; F[Reduce Unplanned Downtime]\n    F --&gt; G{Predict Equipment Failure}\n    style G fill:#f9f,stroke:#333,stroke-width:2px</code></pre> <p>Interpretation: the board\u2011level goal \u201cImprove Financial Performance\u201d cascades to concrete levers. Following the OPEX path: improving production uptime reduces unplanned downtime, which we influence by predicting equipment failure.</p> <p>KPI tree to architecture mapping <pre><code>flowchart LR\n  KPI[Reduce Unplanned Downtime] --&gt; UseCase[PdM Alerts]\n  UseCase --&gt; Arch[Streaming + Lakehouse]\n  Arch --&gt; DataProducts[Telemetry + Work Orders]\n  DataProducts --&gt; Contract[Data Contracts + SLOs]\n  Contract --&gt; Controls[ABAC + Lineage + Quality]\n  Controls --&gt; Pilot[90\u2011Day Pilot Target]</code></pre></p>"},{"location":"day4-why-now/#crossindustry-patterns","title":"Cross\u2011industry patterns","text":"<ul> <li>Telecommunications: Reduce Churn \u2192 Increase Customer Satisfaction \u2192 Proactive Retention Offers \u2192 Predict Churn Intent.</li> <li>Renewables: Increase Energy Yield \u2192 Maximize Asset Availability \u2192 Reduce Repair Time \u2192 Predict Inverter Failures.</li> </ul>"},{"location":"day4-why-now/#interactive-your-value-hypothesis-040055","title":"Interactive: your value hypothesis (0:40\u20130:55)","text":"<p>Use the Value Hypothesis Canvas to tie actions to measurable outcomes.</p> <p>Template: We believe that by doing [INITIATIVE], for [PERSONA], we will achieve [OUTCOME], as measured by [METRIC].</p> <p>Example (O&amp;G): We believe that by implementing a predictive maintenance model for critical compressors, for maintenance planners, we will reduce unplanned downtime, as measured by a 15% reduction in critical equipment failures over the next 6 months.</p> <p>Activity (5\u20137 minutes) 1. Pick a problem in your area. 2. Draft your hypothesis using the template. 3. Identify the KPI and measurement window.</p> <p>Group share (5 minutes): volunteer 1\u20132 examples. Tighten the linkage from initiative \u2192 KPI \u2192 measurement.</p>"},{"location":"day4-why-now/#wrapup-transition-055100","title":"Wrap\u2011up &amp; transition (0:55\u20131:00)","text":"<p>You have articulated \u201cwhy\u201d in measurable business terms. This KPI alignment anchors all architectural and governance decisions. Next, we dive into Reference Architectures for Analytics in Operations\u2014the blueprints for building and scaling these solutions reliably and cost\u2011effectively.</p>"},{"location":"day4-workforce-and-culture/","title":"Workforce and Culture: Roles, Skills, and Adoption","text":""},{"location":"day4-workforce-and-culture/#introduction-the-human-element-of-change","title":"Introduction: the human element of change","text":"<p>Technology succeeds when the operating model supports it. The shift to data products changes how work is organized and who owns outcomes. Key artifacts: RACI template and communications plan outline.</p>"},{"location":"day4-workforce-and-culture/#roles-for-a-productcentric-world","title":"Roles for a product\u2011centric world","text":""},{"location":"day4-workforce-and-culture/#data-product-owner-dpoabbrdata-product-owner","title":"Data Product Owner (DPO{:abbr=\"Data Product Owner\"})","text":"<p>Business domain expert responsible for the success of the data product. - Value: product vision and roadmap aligned to KPI tree - Interface: defines the data contract (schema, semantics, quality) - SLOs: accountable for reliability - Stakeholder management: manages consumers and backlog</p>"},{"location":"day4-workforce-and-culture/#domainaligned-data-engineer","title":"Domain\u2011aligned data engineer","text":"<p>Embedded within the domain; functionally aligned to DPO. - Skills: deep source\u2011system/process knowledge plus core data engineering (streaming, lakehouse) - Focus: build and operate the data product; enforce contract using platform tooling</p>"},{"location":"day4-workforce-and-culture/#platform-team","title":"Platform team","text":"<p>Owning the self\u2011service platform (compute, storage, governance plane) and guardrails; enabling domains rather than executing for them.</p>"},{"location":"day4-workforce-and-culture/#raci-for-clear-ownership","title":"RACI for clear ownership","text":"<p>Use a RACI{:abbr=\"Responsible, Accountable, Consulted, Informed\"} matrix to avoid fallback to centralized habits.</p> <p>Example activities - Define data product SLOs \u2014 A: DPO; R: Domain Engineer; C: Platform Team - Enforce data contract \u2014 A: Platform Team; R: Domain Engineer; C: DPO - Deploy pipeline code \u2014 A: Platform Team; R: Domain Engineer; I: DPO - Manage cloud cost \u2014 A: Platform Team; R: Domain Engineer; I: DPO</p> <pre><code>flowchart TB\n  subgraph Roles\n    DPO[Data Product Owner]\n    DE[Domain Data Engineer]\n    PT[Platform Team]\n  end\n  subgraph Activities\n    SLOs[Define SLOs]\n    Contract[Enforce Contract]\n    Deploy[Deploy Pipelines]\n    Cost[Manage Cost]\n  end\n  DPO --&gt;|A| SLOs\n  DE --&gt;|R| SLOs\n  PT --&gt;|C| SLOs\n  PT --&gt;|A| Contract\n  DE --&gt;|R| Contract\n  DPO --&gt;|C| Contract\n  PT --&gt;|A| Deploy\n  DE --&gt;|R| Deploy\n  DPO --&gt;|I| Deploy\n  PT --&gt;|A| Cost\n  DE --&gt;|R| Cost\n  DPO --&gt;|I| Cost</code></pre> <p>Activity: add a row for \u201cDefine the business meaning (semantics) for a new column.\u201d Answer: A = DPO; R = Domain Engineer; C = Platform Team; I = others.</p> <p>Change management flow <pre><code>flowchart LR\n  Why[Value &amp; KPI Story] --&gt; Champion[Find Domain Champion]\n  Champion --&gt; Pilot[Run 90\u2011Day Pilot]\n  Pilot --&gt; Story[Publish Success Story]\n  Story --&gt; Scale[Onboard Next Domain]\n  Scale --&gt; Normalize[Normalize Roles &amp; RACI]</code></pre></p>"},{"location":"day4-workforce-and-culture/#planning-for-cultural-change-and-adoption","title":"Planning for cultural change and adoption","text":"<p>1) Start with the why (KPI connection) - Tie DPO accountability to tangible outcomes (e.g., completeness +1% \u2192 downtime \u221215%).</p> <p>2) Pilot\u2011first approach - Use the 90\u2011day pilot to trial the model. - Identify a champion domain; co\u2011locate the engineer with business; publish a success story.</p> <p>3) Communications plan - Audience: DPOs, Domain Engineers, Platform Team - Core messages:   - DPOs: \u201cYou own the asset that drives value; we provide tools.\u201d   - Engineers: \u201cMove from reactive service to embedded partner with modern tooling.\u201d - Channels: leadership briefings, engineering workshops, central online hub</p> <pre><code>flowchart LR\n  Why[KPI Value Story] --&gt; Pilot[90\u2011Day Pilot]\n  Pilot --&gt; Story[Success Story]\n  Story --&gt; Scale[Scale to Next Domain]\n  Scale --&gt; Operate[Operating Model Adoption]</code></pre>"},{"location":"day4-workforce-and-culture/#conclusion-and-transition","title":"Conclusion and transition","text":"<p>You now have roles, ownership, and adoption mechanics to make the product model stick. Next: the capstone workshop\u2014re\u2011design a human\u2011machine collaboration and define a concrete 90\u2011day pilot.</p>"},{"location":"day4-workshop-human-machine/","title":"Interactive Workshop: Human\u2011Machine Collaboration Redesign","text":""},{"location":"day4-workshop-human-machine/#introduction-challenge","title":"Introduction &amp; challenge","text":"<p>Synthesize the day\u2019s work into a concrete, well\u2011scoped 90\u2011day Pilot Target. Redesign an operational process (e.g., maintenance alert workflow) to define what the machine does best (prediction, retrieval, optimization) and where humans decide (judgment, safety sign\u2011off).</p>"},{"location":"day4-workshop-human-machine/#phase-1-current-state-and-value-target","title":"Phase 1: current state and value target","text":"<p>1) Pinpoint value and scope - Target KPI (examples): reduce unplanned downtime; improve incident resolution time. - Current process sketch: e.g., Operator sees alert \u2192 calls maintenance \u2192 onsite check \u2192 consults SOP \u2192 orders part.</p> <p>2) Define the single goal for 90 days (examples) - PdM: predictive model for one critical compressor with 90% accuracy; reduce false alarms by 50%. - RAG: internal agent grounded on top 10 SOPs; reduce search time by 30%.</p>"},{"location":"day4-workshop-human-machine/#phase-2-architecting-collaboration-and-governance","title":"Phase 2: architecting collaboration and governance","text":"<p>3) Map technical components - Data Product: name and version; identify the DPO. - Architecture pattern: streaming/edge or retrieval/RAG. - Core feature/model: e.g., rolling\u2011average deviation; anomaly detector.</p> <p>4) Redesign the human\u2011machine workflow - Machine (M): predict/retrieve/suggest. - Human (H): review, approve, execute; human\u2011in\u2011the\u2011loop control point.</p> <pre><code>flowchart LR\n  subgraph Current\n    C1[Alert] --&gt; C2[Call Maintenance]\n    C2 --&gt; C3[Onsite Check]\n    C3 --&gt; C4[Lookup SOP]\n    C4 --&gt; C5[Order Part]\n  end\n  subgraph Redesigned\n    M1[M: Anomaly Detected + Severity] --&gt; M2[M: Draft Work Order via SOPs]\n    M2 --&gt; H1[H: Planner Review &amp; Schedule]\n    H1 --&gt; H2[H: Technician Executes]\n  end</code></pre>"},{"location":"day4-workshop-human-machine/#phase-3-defining-success-and-next-steps","title":"Phase 3: defining success and next steps","text":"<p>5) Control and success criteria - Pilot SLO/SLI: measurable success over 90 days (e.g., \u226590% accuracy). - Governance checkpoint: single most important control (e.g., model dashboard for DPO; output policy check for RAG). - Risk mitigation: primary risk and mitigation (e.g., drift \u2192 retraining triggers; hallucination \u2192 strict grounding + citations).</p> <p>6) Path to production - Day 91 plan: scale to additional assets or domains; expand knowledge base and controls.</p> <pre><code>flowchart TB\n  KPI[Value Hypothesis] --&gt; Arch[Architecture &amp; AI Pattern]\n  Arch --&gt; HMC[Human\u2011Machine Workflow]\n  HMC --&gt; SLO[SLO/SLI &amp; Controls]\n  SLO --&gt; Pilot[90\u2011Day Pilot Target]\n  Pilot --&gt; Scale[Day 91: Scale Plan]</code></pre>"},{"location":"day4-workshop-human-machine/#wrapup-transition-to-day-5","title":"Wrap\u2011up &amp; transition to Day 5","text":"<p>You now have a governed 90\u2011day pilot that connects KPI value, architecture, AI pattern, ownership, and controls. Tomorrow we move to portfolio prioritization, NDPA 2023 compliance, and the platform roadmap to scale to production.</p>"},{"location":"day5-governance-ai-era/","title":"Governance for the AI Era","text":""},{"location":"day5-governance-ai-era/#introduction-necessary-friction-as-an-enabler","title":"Introduction: necessary friction as an enabler","text":"<p>Governance enables scale by reducing chaos, legal risk, and technical debt. Shift from centralized policing to a federated, platform\u2011enabled control model. Core artifact: Governance Controls Checklist.</p>"},{"location":"day5-governance-ai-era/#principle-1-federated-governance-and-the-ownership-shift","title":"Principle 1: federated governance and the ownership shift","text":"<ul> <li>Central governance committee (the \u201cwhat\u201d): sets global policies and intent.</li> <li>Data Product Owners (the \u201chow\u201d): implement controls on their products; accountable for data quality and contract adherence.</li> <li>Platform team (enforcement layer): provides policy\u2011as\u2011code, RBAC/ABAC, logging, lineage, and monitoring so controls are easy to apply and hard to bypass.</li> </ul> <pre><code>flowchart TB\n  Policy[Central Policies (What)] --&gt; Controls[Controls Catalog]\n  Controls --&gt; Platform[Platform Capabilities (How)]\n  Platform --&gt; Domains[Domain Teams (DPO + Engineers)]\n  Domains --&gt; Evidence[Evidence: Logs, Lineage, Dashboards]\n  Evidence --&gt; Committee[Governance Committee Reviews]</code></pre>"},{"location":"day5-governance-ai-era/#principle-2-minimal-viable-control-set-mvcs","title":"Principle 2: minimal viable control set (MVCS)","text":"<p>Prioritize Data, Access, and Model controls.</p>"},{"location":"day5-governance-ai-era/#data-controls-integrity-and-compliance","title":"Data controls (integrity and compliance)","text":"<ul> <li>Mandatory semantics in data contracts; deploy blocked without schema/types/meaning.</li> <li>PII minimization; discovery + masking/tokenization at Silver before Gold.</li> </ul> <p>-### Access controls (security and use) - Least privilege via ABAC{:abbr=\"Attribute\u2011Based Access Control\"}; attributes include region, data class, purpose. - Purpose limitation enforced in access layer; contract declares approved purposes per consumer.</p>"},{"location":"day5-governance-ai-era/#model-controls-ethics-and-performance","title":"Model controls (ethics and performance)","text":"<ul> <li>Human\u2011in\u2011the\u2011loop for safety\u2011critical decisions; DPO approval gate in model registry.</li> <li>Model performance SLOs; automated monitoring for drift/accuracy; alert and rollback on breach.</li> </ul>"},{"location":"day5-governance-ai-era/#tool-mapping-policies-to-controls-checklist","title":"Tool: mapping policies to controls (checklist)","text":"<p>Fill one row per control: - Policy statement (what) - Risk mitigation (why) - Technical control (how) - Owner (A)</p> <p>Example (RAG agent) - Policy: no safety\u2011critical LLM output may contain un\u2011sourced content. - Risk: prevent dangerous advice/asset damage. - Control: output grounding check ensuring all statements cite retrieved sources. - Owner (A): platform team (owns RAG framework tool).</p> <pre><code>flowchart LR\n  P[Policy] --&gt; R[Risk]\n  R --&gt; C[Technical Control]\n  C --&gt; O[Owner (A)]\n  O --&gt; E[Evidence &amp; Monitoring]</code></pre> <p>Exercise: define a FinOps control row for your pilot (e.g., tagging + showback dashboard; Owner: platform team).</p> <p>MVCS overview <pre><code>flowchart TB\n  Policies[Policies] --&gt; DataC[Data Controls]\n  Policies --&gt; AccessC[Access Controls]\n  Policies --&gt; ModelC[Model Controls]\n  DataC --&gt; Enforce1[Contracts, Masking, Retention]\n  AccessC --&gt; Enforce2[ABAC, Purpose Limitation]\n  ModelC --&gt; Enforce3[HITL, Performance SLOs]</code></pre></p>"},{"location":"day5-governance-ai-era/#conclusion-transition","title":"Conclusion &amp; transition","text":"<p>Federated, automated governance provides speed and safety as shared responsibility. Next: Compliance focus\u2014Nigeria NDPA 2023 and global parity, building obligations directly into the lifecycle.</p>"},{"location":"day5-investment-portfolio/","title":"Investment Strategy and Portfolio Shaping","text":""},{"location":"day5-investment-portfolio/#introduction-from-pilot-to-portfolio","title":"Introduction: from pilot to portfolio","text":"<p>Transition from a single successful pilot to a product\u2011centric portfolio that delivers sustained value. Use objective scoring and FinOps principles. Key artifacts: ROI Calculator and Risk Log.</p>"},{"location":"day5-investment-portfolio/#principle-1-value-scoring-and-portfolio-prioritization","title":"Principle 1: value scoring and portfolio prioritization","text":"<p>Use a Value\u2011Risk matrix to score initiatives.</p> <ul> <li>Business value (ROI): monetize KPI impact using the ROI calculator (benefit / fully loaded cost).</li> <li>Implementation risk: assess technical complexity, data availability/quality, and organizational adoption (DPO commitment).</li> </ul> <pre><code>flowchart LR\n  HVLR[Quick Wins\\nHigh Value, Low Risk] --&gt; Prioritize[Prioritize First]\n  HVHR[Strategic Bets\\nHigh Value, High Risk] --&gt; Decompose[Decompose into sub\u2011pilots]\n  LVLR[Maintenance/Sustain\\nLow Value, Low Risk] --&gt; Automate[Automate/Support if required]\n  LVHR[Avoid/Defer\\nLow Value, High Risk] --&gt; Cut[Cut/Defer]</code></pre> <p>Aim pilots at Quick Wins; treat Strategic Bets as sequenced sub\u2011pilots with risk mitigations.</p> <p>Scoring workflow <pre><code>flowchart LR\n  Ideas[Use\u2011Case Backlog] --&gt; ROI[ROI Calculator]\n  Ideas --&gt; Risk[Risk Log]\n  ROI --&gt; Matrix[Value\u2011Risk Matrix]\n  Risk --&gt; Matrix\n  Matrix --&gt; Prioritize[Prioritized Portfolio]\n  Prioritize --&gt; Fund[Fund 90\u2011Day Pilots]</code></pre></p>"},{"location":"day5-investment-portfolio/#principle-2-finops-for-data-and-ai-initiatives","title":"Principle 2: FinOps for data and AI initiatives","text":"<p>Bring financial accountability to variable cloud spend.</p> <p>1) Cost transparency &amp; showback - Tag resources with product and DPO; show cost dashboards back to domain owners.</p> <p>2) Efficiency and optimization - Data tiering (Bronze to cold storage; Gold on hot compute) - Right\u2011size/ephemeral compute; serverless where possible - Budget thresholds and alerts (e.g., &gt;20% over forecast)</p> <p>3) Forecasting and budgeting - Use historical consumption to forecast similar products.</p> <pre><code>flowchart LR\n  Tag[Tagging &amp; Cost Collection] --&gt; Show[Showback Dashboards]\n  Show --&gt; Opt[Optimization Actions]\n  Opt --&gt; Forecast[Forecast &amp; Budget]\n  Forecast --&gt; Govern[Thresholds &amp; Alerts]\n  Govern --&gt; Show</code></pre>"},{"location":"day5-investment-portfolio/#tool-quantifying-and-mitigating-risk-risk-log","title":"Tool: quantifying and mitigating risk (Risk Log)","text":"<p>Risk categories and sample mitigations: - Data contract risk: require formal contracts with source owners before funding - AI/model risk: add human\u2011in\u2011the\u2011loop and model performance SLOs - Compliance/governance risk (NDPA 2023): mask/tokenize PII at Silver; controls to follow in governance session</p> <p>Interactive exercise: score your pilot\u2019s top 3 risks with impact, likelihood, and mitigation; update the Risk Log.</p>"},{"location":"day5-investment-portfolio/#conclusion-transition-to-governance","title":"Conclusion &amp; transition to governance","text":"<p>You can now: - Score initiatives by ROI and risk - Apply FinOps to make costs transparent and optimized at the product level - Proactively mitigate risks before execution</p> <p>Next: Governance for the AI Era\u2014mapping policies to technical controls for data, models, and access.</p>"},{"location":"day5-ndpa-compliance/","title":"Compliance Focus: Nigeria NDPA 2023 and Global Parity","text":""},{"location":"day5-ndpa-compliance/#introduction-mandate-of-trust-and-law","title":"Introduction: mandate of trust and law","text":"<p>Compliance is a license to operate. NDPA 2023 establishes obligations enforced by the NDPC. Compliance is shared across Legal, DPOs, and engineers; build it into delivery using DPIA and data transfer assessments.</p>"},{"location":"day5-ndpa-compliance/#ndpa-2023-core-principles-and-ndpc","title":"NDPA 2023: core principles and NDPC","text":"<p>Seven pillars to encode in contracts and controls: - Lawfulness, fairness, transparency - Purpose limitation - Data minimization - Accuracy - Storage limitation (retention) - Integrity and confidentiality (security) - Accountability</p> <pre><code>flowchart TD\n  subgraph Regulatory\n    NDPC[NDPC \u2014 Nigeria Data Protection Commission]\n  end\n  subgraph Business\n    Legal[Legal &amp; Compliance Office]\n    DPO[Domain Data Product Owner]\n  end\n  subgraph Technical\n    DP[Data Product Pipeline]\n    AC[Access Control Layer]\n    Consumer[Data Consumer/App]\n  end\n\n  NDPC -- Enforces law &amp; penalties --&gt; Legal\n  Legal -- Policy &amp; DPIA mandate --&gt; DPO\n  DPO -- Contract requirements --&gt; DP\n  DP -- Masking, retention, purpose checks --&gt; AC\n  AC -- Purpose\u2011limited access --&gt; Consumer\n\n  style NDPC fill:#f9f,stroke:#333\n  style Legal fill:#ccf,stroke:#333\n  style DPO fill:#cfc,stroke:#333</code></pre>"},{"location":"day5-ndpa-compliance/#technical-integration-across-lakehouse-layers","title":"Technical integration across lakehouse layers","text":"<ul> <li>Bronze (ingestion control): retention tags and lifecycle policies for storage limitation and integrity.</li> <li>Silver (transformation control): data minimization via masking/pseudonymization/tokenization before joins and conformance.</li> <li>Gold (access control): purpose limitation and accountability using ABAC; serve minimal aggregated data.</li> </ul> <p>Layered compliance defense <pre><code>flowchart LR\n  Bronze[Bronze: Retention Tagged] --&gt; Silver[Silver: Mask/Tokenize]\n  Silver --&gt; Gold[Gold: Aggregated + ABAC]\n  Gold --&gt; Audit[Evidence: Logs/Lineage]</code></pre></p>"},{"location":"day5-ndpa-compliance/#tooling-dpia-and-crossborder-transfer-assessment","title":"Tooling: DPIA and cross\u2011border transfer assessment","text":"<ul> <li>DPIA: required for high\u2011risk processing and new AI deployments; document processing, necessity, risks, mitigations; DPO + Legal approve before production.</li> <li>Data transfer assessment (global parity): ensure adequacy or implement SCCs/BCRs; encrypt in transit/at rest; evaluate destination legal conflicts.</li> </ul>"},{"location":"day5-ndpa-compliance/#summary-and-transition","title":"Summary and transition","text":"<p>Make the DPO accountable for principles; minimize at Silver; enforce purpose at Gold; perform DPIA and transfer assessments. Next: quality, observability, and reliability\u2014SLOs/SLIs to keep products dependable.</p>"},{"location":"day5-platform-blueprint/","title":"Platform Blueprint and Reference Implementation Plan","text":""},{"location":"day5-platform-blueprint/#introduction-the-platform-as-enabler-of-trust","title":"Introduction: the platform as enabler of trust","text":"<p>The data platform is a product that enables domain teams to launch governed, compliant, reliable data products without ticket queues. It enforces our operating model and provides self\u2011service tooling.</p>"},{"location":"day5-platform-blueprint/#part-1-mandate-selfservice-and-automation","title":"Part 1: mandate \u2014 self\u2011service and automation","text":"<p>Platform team treats the platform as a product with its own roadmap, SLOs, and DPO. Capabilities include CI/CD, lineage, RBAC/ABAC policy\u2011as\u2011code, and FinOps showback.</p> <pre><code>flowchart TD\n  subgraph Central_Platform_Team\n    A[Self\u2011Service CI/CD]\n    B[Automated Observability]\n    C[Access Control Policy Engine]\n  end\n  subgraph Domain_Team\n    DPO(Data Product Owner)\n    DE[Domain Engineer]\n  end\n  subgraph Infrastructure\n    Infra(Cloud Compute/Storage/Network)\n  end\n\n  DE -- Uses Tools --&gt; A\n  DE -- Uses Tools --&gt; B\n  DE -- Uses Tools --&gt; C\n\n  A --&gt; Infra\n  B --&gt; DE\n  C --&gt; Infra\n\n  style A fill:#AEEEEE,stroke:#333\n  style B fill:#AEEEEE,stroke:#333\n  style C fill:#AEEEEE,stroke:#333\n  style DPO fill:#FFCC66,stroke:#333\n  style DE fill:#FFCC66,stroke:#333</code></pre>"},{"location":"day5-platform-blueprint/#part-2-strategic-blueprints-data-fabric-vs-data-mesh","title":"Part 2: strategic blueprints \u2014 data fabric vs data mesh","text":"<p>Both address silos; differ on ownership and control plane.</p> <pre><code>flowchart LR\n  subgraph Data_Fabric\n    F1[Source: SAP]\n    F2[Source: Sensor Lake]\n    F3[Source: HR DB]\n    CGF[Central Governance Fabric]\n    CGF -- Metadata/Virtualization --&gt; F1\n    CGF -- Metadata/Virtualization --&gt; F2\n    CGF -- Metadata/Virtualization --&gt; F3\n    CGF --&gt; ConsF[Consumers]\n    style CGF fill:#ADD8E6,stroke:#333\n  end\n\n  subgraph Data_Mesh\n    P[Central Platform Tools]\n    D1[Domain A: Upstream Product]\n    D2[Domain B: Logistics Product]\n    D1 -- Enforced by --&gt; P\n    D2 -- Enforced by --&gt; P\n    D1 -- Data Contract --&gt; ConsM[Consumers]\n    D2 -- Data Contract --&gt; ConsM\n    style P fill:#FFC0CB,stroke:#333\n  end</code></pre> <p>Mesh aligns with decentralized product ownership enforced by a central platform; Fabric centralizes integration and virtualization\u2014choose based on culture and complexity.</p>"},{"location":"day5-platform-blueprint/#part-3-phased-implementation-roadmap","title":"Part 3: phased implementation roadmap","text":"<p>Crawl\u2011walk\u2011run over ~3 years.</p> <ul> <li>Phase 1: Foundation &amp; Pilot (0\u20139 months)</li> <li>Architecture: basic lakehouse (Bronze/Silver/Gold) for one product</li> <li>Governance: initial FinOps showback; RBAC/ABAC for pilot</li> <li> <p>Org: onboard first 1\u20132 DPOs; achieve pilot SLOs/ROI</p> </li> <li> <p>Phase 2: Expansion &amp; Self\u2011Service (9\u201318 months)</p> </li> <li>Platform: self\u2011service CI/CD; automated lineage &amp; observability</li> <li>Compliance: tokenization/masking at Silver; NDPA alignment</li> <li> <p>Org: onboard 10\u201315 DPOs across 3 business units; retire 3\u20135 silos</p> </li> <li> <p>Phase 3: Scale &amp; Automation (18+ months)</p> </li> <li>AI/ML: mature feature store &amp; model registry; support agents</li> <li>Global parity: automate data transfer assessments (SCCs/BCRs)</li> <li>Architecture: streaming/edge across relevant sites; platform focuses on innovation</li> </ul>"},{"location":"day5-platform-blueprint/#conclusion","title":"Conclusion","text":"<p>The platform is the factory floor for data products\u2014productized, self\u2011service, and governed. Next: capstone workshop\u2014translate the 90\u2011day pilot into an executive one\u2011pager and an IT implementation brief.</p> <p>Roadmap overview <pre><code>flowchart TB\n  P1[Phase 1: Foundation &amp; Pilot] --&gt; P2[Phase 2: Expansion &amp; Self\u2011Service]\n  P2 --&gt; P3[Phase 3: Scale &amp; Automation]\n  P1 --&gt; ROI[Prove ROI &amp; SLOs]\n  P2 --&gt; Retire[Retire Silos]\n  P3 --&gt; Innovate[Platform Focus: Innovation]</code></pre></p>"},{"location":"day5-quality-observability/","title":"Quality, Observability, and Reliability","text":""},{"location":"day5-quality-observability/#introduction-the-cost-of-untrustworthy-data","title":"Introduction: the cost of untrustworthy data","text":"<p>Reliability is the new security. If data is wrong or late, AI and decisions fail. Establish SLOs/SLIs and observability so the promises in Data Contracts are measurable and enforceable. Artifact: Lineage + Observability Checklist.</p>"},{"location":"day5-quality-observability/#part-1-defining-reliability-with-slos-and-slis","title":"Part 1: defining reliability with SLOs and SLIs","text":"<ul> <li>SLI: raw metric (e.g., freshness latency Bronze\u2192Gold)</li> <li>SLO: target for the SLI over time (e.g., 99.5% within 60 minutes over 30 days)</li> <li>SLA: consequence/error budget</li> </ul> <pre><code>flowchart TD\n  A[Business Requirement: Reduce Unplanned Downtime] --&gt; B[Data Product Owner]\n  B --&gt; C[Data Contract]\n  C -- Sets Target --&gt; D[SLO: 99.5% Data Completeness]\n  D -- Requires Measurement --&gt; E[SLI: % NULLs in Key Column]\n  E --&gt; F[Platform Monitoring System]\n  F -- Failure Alert --&gt; B</code></pre> <p>SLOs convert business need into measurable commitments; the platform measures SLIs and alerts on breach.</p> <p>SLO management loop <pre><code>flowchart LR\n  Define[Define SLOs] --&gt; Instrument[Instrument SLIs]\n  Instrument --&gt; Monitor[Monitor Dashboards]\n  Monitor --&gt; Alert[Alert on Breach]\n  Alert --&gt; Triage[Root Cause via Logs/Lineage]\n  Triage --&gt; Fix[Fix Pipeline/Config]\n  Fix --&gt; Review[Review Error Budget]\n  Review --&gt; Define</code></pre></p>"},{"location":"day5-quality-observability/#part-2-the-core-three-slis","title":"Part 2: the core three SLIs","text":"<ul> <li>Freshness (timeliness): delta between event_timestamp and processing_timestamp; example target 99.9% &lt; 5 minutes for PdM.</li> <li>Completeness (presence/volume): records received vs expected; % non\u2011NULL in key fields; example \u226599.5% wells daily and \u226599% non\u2011NULL production_volume.</li> <li>Accuracy (semantic/constraint): % values within valid ranges (e.g., 500\u20131,500 PSI); target \u226598%.</li> </ul>"},{"location":"day5-quality-observability/#part-3-full-data-observability-and-lineage","title":"Part 3: full data observability and lineage","text":"<p>Observability explains why failures happen using Metrics, Logs, and Traces (lineage).</p> <pre><code>flowchart TD\n  A[Data Product] --&gt; B(Metrics)\n  A --&gt; C(Logs)\n  A --&gt; D(Traces/Lineage)\n\n  B -- SLIs/SLOs --&gt; E[Data Quality Dashboard]\n  C -- Error Stack --&gt; F[Debug Pipeline Failure]\n  D -- End\u2011to\u2011End Flow --&gt; G[Impact Analysis]\n\n  style A fill:#FFD700,stroke:#333\n  style E fill:#ccf,stroke:#333\n  style G fill:#ffc,stroke:#333</code></pre> <ul> <li>Metrics: what is wrong (freshness/completeness/accuracy trends)</li> <li>Logs: where in code it failed</li> <li>Traces/Lineage: who is impacted; supports governance questions (e.g., NDPA masking at Silver) and safe deprecations</li> </ul>"},{"location":"day5-quality-observability/#activity-apply-the-checklist","title":"Activity: apply the checklist","text":"<p>1) Choose the most critical SLI for your pilot. 2) Set an SLO target. 3) Identify the lineage you must see when the SLO breaches (affected models/dashboards).</p>"},{"location":"day5-quality-observability/#conclusion-transition","title":"Conclusion &amp; transition","text":"<p>You\u2019ve established measurable reliability and deep diagnosis. Next: the platform blueprint and reference implementation plan\u2014who builds the tooling (lineage, serverless compute, CI/CD) and how to deliver it in phases.</p>"},{"location":"day5-workshop-pilot-to-production/","title":"Interactive Workshop: Pilot Plan to Production Path","text":""},{"location":"day5-workshop-pilot-to-production/#introduction-challenge","title":"Introduction &amp; challenge","text":"<p>Convert the 90\u2011day pilot design into two artifacts: an Executive One\u2011Pager (value, risk, readiness) and an IT Implementation Brief (architecture, tooling, controls). First half: business case. Second half: technical plan.</p>"},{"location":"day5-workshop-pilot-to-production/#phase-1-executive-onepager-the-business-case","title":"Phase 1: executive one\u2011pager (the business case)","text":"<ul> <li>Value proposition &amp; ROI</li> <li>Project title (business\u2011centric)</li> <li>Targeted KPI and current state</li> <li>Current cost/loss quantified</li> <li>90\u2011day goal and estimated ROI using the ROI calculator</li> <li>Ownership: name the DPO and business unit</li> <li>Risk &amp; organizational readiness</li> <li>Value\u2011Risk matrix score (Quick Win / Strategic Bet)</li> <li>Top 3 risks with paired mitigations (from Risk Log)</li> <li>Day 91 scaling path (phase 2 scope and benefits)</li> </ul>"},{"location":"day5-workshop-pilot-to-production/#phase-2-it-implementation-brief-the-technical-plan","title":"Phase 2: IT implementation brief (the technical plan)","text":"<ul> <li>Architecture &amp; data product definition</li> <li>Product names and versions; Data Contract reference (schema, semantics)</li> <li>Platform tooling requests (self\u2011service CI/CD, lineage, policy engine)</li> <li>Primary pattern and layer focus (e.g., hybrid streaming/lakehouse; edge\u2192Bronze/Silver)</li> <li>Governance &amp; compliance controls</li> <li>NDPA (PII) controls: tokenization/masking at Silver</li> <li>Reliability SLOs/SLIs: freshness/completeness targets</li> <li>Access/security: ABAC rules via platform policy engine</li> </ul> <pre><code>sequenceDiagram\n  participant S as Source System (SCADA/IoT)\n  participant T as Platform: Tokenization Service\n  participant AC as Platform: Access Control\n  participant DPE as Domain Product Engineer\n  participant DPO as Data Product Owner\n  participant A as AI/BI Consumer\n\n  DPE-&gt;&gt;T: Ingest Data (incl. PII)\n  T--&gt;&gt;DPE: Masked Data (Silver)\n\n  DPE-&gt;&gt;AC: Publish Product + Contract + SLOs\n  DPO-&gt;&gt;AC: Configure ABAC (Region: Delta, Role: Planner)\n\n  A-&gt;&gt;AC: Request Gold Data for PdM\n  alt Compliance Check\n    AC--&gt;&gt;A: Deny (role/region mismatch)\n  else Access Approved\n    AC--&gt;&gt;A: Serve Gold Data (masked)\n  end</code></pre> <p>Artifacts handoff <pre><code>flowchart LR\n  OnePager[Executive One\u2011Pager] --&gt; Approve[Investment Approval]\n  Brief[IT Implementation Brief] --&gt; Provision[Platform Provisioning]\n  Approve --&gt; Provision\n  Provision --&gt; Build[Build &amp; Configure]\n  Build --&gt; Launch[Pilot Launch]</code></pre></p>"},{"location":"day5-workshop-pilot-to-production/#conclusion","title":"Conclusion","text":"<p>Two outputs ready for leadership and engineering: the executive one\u2011pager and the implementation brief. These secure funding and guide delivery from pilot to production.</p>"},{"location":"glossary/","title":"Glossary","text":"<p>Tip: Use abbreviations like this in pages to get instant hover help: <code>DaaP</code>, <code>ABAC</code>. The entries below provide fuller definitions.</p>"},{"location":"glossary/#architecture-operating-model","title":"Architecture &amp; operating model","text":"<ul> <li>Data\u2011as\u2011a\u2011Product (DaaP): Treating data artifacts and services as owned products with clear purpose, versioning, and SLOs; owned by a Data Product Owner (DPO) and delivered by a domain team.</li> <li>Data Product Owner (DPO): Business\u2011side owner accountable for value, contract, and SLOs of a data product; sets roadmap from KPI tree; approves model releases for safety\u2011critical use.</li> <li>Data Contract: Machine\u2011readable agreement defining schema, semantics, quality/freshness SLOs, PII handling, lifecycle, and purpose limitations for consumers.</li> <li>Medallion Lakehouse (Bronze/Silver/Gold): Layered refinement pattern for raw\u2192conformed\u2192business\u2011ready data with retention at Bronze, minimization at Silver, and access controls at Gold.</li> <li>Data Mesh: Organizational and architectural paradigm where domains own data products, enforced by central platform standards and tooling.</li> <li>Data Fabric: Centralized integration and metadata/virtualization layer that connects disparate sources with a unified access plane.</li> <li>Feature/Embedding Store: Central service to publish and reuse engineered features and embeddings consistently across models and agents.</li> <li>Streaming/Edge Analytics: Processing data in motion with local edge filtering and central streaming bus to meet tight latency SLOs.</li> </ul>"},{"location":"glossary/#governance-compliance-security","title":"Governance, compliance &amp; security","text":"<ul> <li>Federated Governance: Split of policy intent (central) and control execution (domains) enforced by platform capabilities.</li> <li>ABAC (Attribute\u2011Based Access Control): Policies evaluate attributes of user, data, and context (e.g., role=Planner, region=Delta, purpose=Forecasting).</li> <li>Policy\u2011as\u2011Code: Declarative rules enforced automatically at runtime by the platform (e.g., access engine, data masking policies).</li> <li>NDPA 2023: Nigeria Data Protection Act establishing principles (lawfulness, purpose limitation, minimization, accuracy, storage limitation, security, accountability) and the NDPC regulator.</li> <li>DPIA: Data Protection Impact Assessment for high\u2011risk processing; documents processing, necessity, risks, mitigations; approved by Legal and DPO before production.</li> <li>Cross\u2011Border Transfer Assessment: Adequacy check or SCCs/BCRs plus encryption and legal review before exporting personal data.</li> <li>RACI: Responsibility matrix clarifying who is Responsible, Accountable, Consulted, and Informed for a task.</li> </ul>"},{"location":"glossary/#reliability-observability","title":"Reliability &amp; observability","text":"<ul> <li>SLI (Service Level Indicator): Measurable signal of reliability or data quality (e.g., freshness latency, completeness %, valid\u2011range accuracy).</li> <li>SLO (Service Level Objective): Target for an SLI over a window (e.g., 99.5% completeness daily over 30 days); forms the core of the product promise.</li> <li>SLA (Service Level Agreement): Formal consequence or error budget policy when SLOs are breached.</li> <li>Lineage: End\u2011to\u2011end trace of data flow and transformations; supports impact analysis, audits, and responsible deprecations.</li> <li>Metrics/Logs/Traces: Three pillars of observability; metrics carry SLIs, logs aid debugging, traces/lineage show dependencies and impact.</li> </ul>"},{"location":"glossary/#ai-patterns","title":"AI patterns","text":"<ul> <li>RAG (Retrieval\u2011Augmented Generation): Ground LLM outputs with retrieved documents (hybrid search: keyword + vector) and provide citations.</li> <li>Agentic Workflow: Tool\u2011using, planning agents governed by input/output policies and human\u2011in\u2011the\u2011loop checkpoints.</li> <li>Model Registry: System of record for models with versions, lineage, approvals, and performance metrics; gates promotion to production.</li> </ul>"},{"location":"glossary/#finops-investment","title":"FinOps &amp; investment","text":"<ul> <li>FinOps: Financial accountability for variable cloud spend; tagging, showback, optimization, forecasting, thresholds/alerts at product level.</li> <li>Value\u2011Risk Matrix: Portfolio tool to categorize initiatives (Quick Wins, Strategic Bets, Sustain, Avoid) using ROI and risk scores.</li> <li>ROI Calculator: Quantifies benefits vs fully\u2011loaded costs (engineering, licenses, cloud) to prioritize investments.</li> <li>ROI: Return on Investment; ratio of net benefit to cost used to compare initiatives.</li> </ul>"},{"location":"glossary/#nigeria-local-context","title":"Nigeria &amp; local context","text":"<ul> <li>NDPC: Nigeria Data Protection Commission\u2014regulator for NDPA 2023.</li> <li>N\u2011ATLAS: Nigeria\u2019s open\u2011source multilingual/multimodal LLM (Yoruba, Hausa, Igbo, Nigerian\u2011accented English) for localized interactions and documentation.</li> </ul> <p>Concept map <pre><code>flowchart LR\n  DataProduct -- Contract --&gt; Consumer\n  DataProduct -- Lineage --&gt; Catalog\n  Catalog -- Policies --&gt; Access\n  Access -- ABAC --&gt; Consumer</code></pre></p> <p>Compliance lifecycle <pre><code>flowchart TB\n  Plan --&gt; DPIA --&gt; Build --&gt; Validate --&gt; Operate --&gt; Review\n  Validate --&gt; Register[Model/Data Register]\n  Operate --&gt; Monitor[Monitoring &amp; Incidents]</code></pre></p>"},{"location":"resources/","title":"Resources and References","text":"<p>Standards and frameworks - DAMA-DMBOK2 \u2014 Data Management Body of Knowledge - EDM Council DCAM \u2014 Data Management Capability Assessment Model - EDM Council CDMC \u2014 Cloud Data Management Capabilities - NIST AI RMF 1.0 and Generative AI Profile - EU AI Act (obligations and timelines) - ISO/IEC 42001 \u2014 AI management system standard - ISO 8000 \u2014 Data quality - ISO/IEC 27001 \u2014 Information security management</p> <p>Nigeria regulations and guidance - NDPA 2023 \u2014 Nigeria Data Protection Act - NDPC \u2014 Nigeria Data Protection Commission; registration/licensing guidance - Cross-border transfer safeguards and DPIA guidance</p> <p>Architecture patterns and practices - Data mesh vs data fabric decision guides - Lakehouse and medallion architecture - Streaming and edge analytics - Knowledge graph + vector search integration - Feature/embedding stores</p> <p>Governance and controls - Policy-to-control mapping and control catalogs - Data contracts lifecycle (schema, semantics, SLOs) - Lineage (e.g., OpenLineage patterns), observability SLIs/SLOs - Access governance (ABAC, attribute tagging) - DSPM concepts for sensitive data</p> <p>RAG/LLMOps - Retrieval quality evaluation, safety filtering, source attribution - Risk registers and red-teaming playbooks - Multilingual/local models: N-ATLAS for Yoruba/Hausa/Igbo/Nigerian-accented English</p> <p>Measurement and FinOps - ROI and risk scoring for data/AI portfolios - Cost-to-serve models and SLO-driven optimization</p> <p>Recommended reading - Data product thinking and operating models - Data quality and observability handbooks - Model governance and AI policy primers</p> <p>Architecture overview <pre><code>flowchart LR\n  Sources --&gt; Ingest --&gt; Lakehouse --&gt; Serving\n  Lakehouse --&gt; Catalog\n  Catalog --&gt; Users\n  Serving --&gt; Apps</code></pre></p> <p>Governance overview <pre><code>flowchart TB\n  Policies --&gt; Controls --&gt; TechControls --&gt; Evidence --&gt; Audit\n  Controls --&gt; ProcControls</code></pre></p>"},{"location":"worksheets/","title":"Worksheets and Templates","text":"<p>Use directly in workshops; keep vendor-agnostic. Export to Teams or your preferred tool.</p> <p>Templates - KPI tree template (use-case -&gt; KPI -&gt; measure -&gt; baseline -&gt; target) - Value hypothesis canvas (assumptions, risks, leading indicators) - Data product canvas (purpose, owner, consumers, SLOs, versioning) - Data contract template (schema, semantics, freshness, quality thresholds, PII) - RAG risk register (risks, mitigations, evaluation metrics, fallback) - ROI calculator (benefits, costs, risk-adjusted value) - Lineage/observability checklist (SLIs, alerts, incident runbook)</p> <p>Data product lifecycle <pre><code>flowchart TB\n  Ideate --&gt; Define --&gt; Build --&gt; Validate --&gt; Operate --&gt; Improve\n  Define --&gt;|Contract| Build\n  Operate --&gt;|SLO reports| Improve</code></pre></p> <p>Governance workflow <pre><code>flowchart LR\n  Policy --&gt; Controls --&gt; Implementation --&gt; Evidence --&gt; Audit\n  Implementation --&gt; Monitoring\n  Monitoring --&gt; Evidence</code></pre></p> <p>Downloadable stubs (to be added) - data_product_canvas.md - data_contract_template.md - rag_risk_register.md - roi_calculator.xlsx - lineage_checklist.md</p>"}]}